# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11DdtzvYIvMVu5uXQG_dVtg_5GufUSF-X
"""

from google.colab import drive
drive.mount('/content/drive')

# ===== ë°ì´í„° ë¡œë“œ =====

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# í•œê¸€ í°íŠ¸ ì„¤ì • (ì½”ë©)
plt.rcParams['font.family'] = 'NanumGothic'
plt.rcParams['axes.unicode_minus'] = False

# íŒŒì¼ ë¡œë“œ
df_need = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/mhvi_project/need_tidy.csv')
df_supply = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/mhvi_project/supply_tidy.csv')

# í†µí•©
df = df_need.merge(df_supply, on='district', how='inner')

print("=" * 60)
print("ğŸ“Š ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
print("=" * 60)
print(f"Shape: {df.shape}")
print(f"êµ¬ ê°œìˆ˜: {len(df)}")
print(f"ë³€ìˆ˜ ê°œìˆ˜: {len(df.columns) - 1}")

print("\në³€ìˆ˜ ëª©ë¡:")
print("Need (11ê°œ):", df_need.columns.tolist()[1:])
print("Supply (9ê°œ):", df_supply.columns.tolist()[1:])

print("\nì²« 5ê°œ êµ¬:")
print(df.head())

print("\nê¸°ì´ˆ í†µê³„:")
print(df.describe())

print("\nê²°ì¸¡ì¹˜ í™•ì¸:")
print(df.isnull().sum().sum())

print("\nâœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!")

# ===== ì •ê·œí™” í•¨ìˆ˜ =====

from sklearn.preprocessing import MinMaxScaler

def normalize_to_100(series, direction='positive'):
    """
    0~100ì ìœ¼ë¡œ ì •ê·œí™”

    direction:
    - 'positive': ë†’ì„ìˆ˜ë¡ ë‚˜ì¨ (ìì‚´ë¥ , ìš°ìš¸ê° ë“±)
    - 'negative': ë‚®ì„ìˆ˜ë¡ ë‚˜ì¨ (ì¸í”„ë¼ ë“±)
    """
    scaler = MinMaxScaler(feature_range=(0, 100))

    if direction == 'positive':
        # ë†’ì„ìˆ˜ë¡ 100ì 
        normalized = scaler.fit_transform(series.values.reshape(-1, 1))
    else:
        # ë‚®ì„ìˆ˜ë¡ 100ì  (ì—­ì „)
        normalized = 100 - scaler.fit_transform(series.values.reshape(-1, 1))

    return normalized.flatten()

print("=" * 60)
print("ğŸ“ Step 2: ë³€ìˆ˜ ì •ê·œí™”")
print("=" * 60)

# Need ë³€ìˆ˜ ì •ê·œí™” (ë†’ì„ìˆ˜ë¡ ìœ„í—˜ = 100ì )
need_vars = [
    'suicide_rate',
    'depression_experience_rate',
    'perceived_stress_rate',
    'high_risk_drinking_rate',
    'unmet_medical_need_rate',
    'unemployment_rate',
    'elderly_population_rate',
    'old_dependency_ratio',
    'single_households',
    'basic_livelihood_recipients'
]

df_need_norm = df[['district']].copy()

for var in need_vars:
    df_need_norm[f'{var}_norm'] = normalize_to_100(df[var], direction='positive')
    print(f"  âœ… {var:40s} â†’ ì •ê·œí™” ì™„ë£Œ")

# Supply ë³€ìˆ˜ ì •ê·œí™” (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ = ì—­ì „ í•„ìš”)
supply_vars = [
    'welfare_budget_per_capita',
    'public_sports_facilities_count',
    'parks_count',
    'libraries_count',
    'medical_institutions_count',
    'health_promotion_centers_count',
    'elderly_leisure_welfare_facilities_count',
    'in_home_elderly_welfare_facilities_count',
    'cultural_satisfaction'
]

df_supply_norm = df[['district']].copy()

for var in supply_vars:
    df_supply_norm[f'{var}_norm'] = normalize_to_100(df[var], direction='negative')
    print(f"  âœ… {var:40s} â†’ ì •ê·œí™” ì™„ë£Œ")

print("\nì •ê·œí™” ê²°ê³¼ ìƒ˜í”Œ:")
print(df_need_norm.head())

print("\nâœ… Step 2 ì™„ë£Œ: ëª¨ë“  ë³€ìˆ˜ 0~100ì  ë³€í™˜")

# ===== Need Index ê³„ì‚° =====

print("\n" + "=" * 60)
print("ğŸ“Š Step 3: Need Index ê³„ì‚°")
print("=" * 60)

# ê°€ì¤‘ì¹˜ ì„¤ì •
weights_need = {
    # ì •ì‹ ê±´ê°• ì§ì ‘ ì§€í‘œ (50%)
    'suicide_rate_norm': 0.15,
    'depression_experience_rate_norm': 0.12,
    'perceived_stress_rate_norm': 0.12,
    'high_risk_drinking_rate_norm': 0.11,

    # ì‚¬íšŒê²½ì œì  ì·¨ì•½ì„± (40%)
    'elderly_population_rate_norm': 0.10,
    'single_households_norm': 0.10,
    'basic_livelihood_recipients_norm': 0.10,
    'unemployment_rate_norm': 0.10,

    # ì˜ë£Œ ì ‘ê·¼ì„± (10%)
    'unmet_medical_need_rate_norm': 0.05,
    'old_dependency_ratio_norm': 0.05
}

print("ê°€ì¤‘ì¹˜:")
total_weight = 0
for var, weight in weights_need.items():
    print(f"  {var:45s}: {weight:5.1%}")
    total_weight += weight

print(f"\nì´ ê°€ì¤‘ì¹˜ í•©: {total_weight:.1%}")

# Need Index ê³„ì‚°
df_need_norm['Need_Index'] = 0

for var, weight in weights_need.items():
    df_need_norm['Need_Index'] += df_need_norm[var] * weight

# ì •ë ¬
df_need_norm_sorted = df_need_norm.sort_values('Need_Index', ascending=False)

print("\nğŸ“ˆ Need Index TOP 10 (ìœ„í—˜ë„ ë†’ì€ ìˆœ):")
print(df_need_norm_sorted[['district', 'Need_Index']].head(10).to_string(index=False))

print("\nğŸ“‰ Need Index BOTTOM 5 (ìœ„í—˜ë„ ë‚®ì€ ìˆœ):")
print(df_need_norm_sorted[['district', 'Need_Index']].tail(5).to_string(index=False))

print(f"\ní‰ê· : {df_need_norm['Need_Index'].mean():.2f}")
print(f"ìµœëŒ€: {df_need_norm['Need_Index'].max():.2f}")
print(f"ìµœì†Œ: {df_need_norm['Need_Index'].min():.2f}")

print("\nâœ… Step 3 ì™„ë£Œ: Need Index")

# ===== Supply Index ê³„ì‚° =====

print("\n" + "=" * 60)
print("ğŸ¥ Step 4: Supply Index ê³„ì‚°")
print("=" * 60)

# ê°€ì¤‘ì¹˜ ì„¤ì • (SupplyëŠ” ë‚®ì„ìˆ˜ë¡ ë¬¸ì œ)
weights_supply = {
    # ì •ì‹ ê±´ê°• ì§ì ‘ ì¸í”„ë¼ (40%)
    'health_promotion_centers_count_norm': 0.20,
    'medical_institutions_count_norm': 0.20,

    # ì‚¬íšŒë³µì§€ ì¸í”„ë¼ (30%)
    'elderly_leisure_welfare_facilities_count_norm': 0.15,
    'in_home_elderly_welfare_facilities_count_norm': 0.15,

    # ì‚¶ì˜ ì§ˆ ì¸í”„ë¼ (30%)
    'parks_count_norm': 0.10,
    'libraries_count_norm': 0.07,
    'public_sports_facilities_count_norm': 0.07,
    'cultural_satisfaction_norm': 0.03,
    'welfare_budget_per_capita_norm': 0.03
}

print("ê°€ì¤‘ì¹˜:")
total_weight = 0
for var, weight in weights_supply.items():
    print(f"  {var:50s}: {weight:5.1%}")
    total_weight += weight

print(f"\nì´ ê°€ì¤‘ì¹˜ í•©: {total_weight:.1%}")

# Supply Index ê³„ì‚° (ë‚®ì„ìˆ˜ë¡ ë¬¸ì œ = ì—­ì „ í•„ìš”)
df_supply_norm['Supply_Index'] = 0

for var, weight in weights_supply.items():
    df_supply_norm['Supply_Index'] += (100 - df_supply_norm[var]) * weight

# ì •ë ¬
df_supply_norm_sorted = df_supply_norm.sort_values('Supply_Index', ascending=False)

print("\nğŸ“ˆ Supply Index TOP 10 (ì¸í”„ë¼ ë¶€ì¡±í•œ ìˆœ):")
print(df_supply_norm_sorted[['district', 'Supply_Index']].head(10).to_string(index=False))

print("\nğŸ“‰ Supply Index BOTTOM 5 (ì¸í”„ë¼ í’ë¶€í•œ ìˆœ):")
print(df_supply_norm_sorted[['district', 'Supply_Index']].tail(5).to_string(index=False))

print(f"\ní‰ê· : {df_supply_norm['Supply_Index'].mean():.2f}")
print(f"ìµœëŒ€: {df_supply_norm['Supply_Index'].max():.2f}")
print(f"ìµœì†Œ: {df_supply_norm['Supply_Index'].min():.2f}")

print("\nâœ… Step 4 ì™„ë£Œ: Supply Index")

# ===== Gap Index ê³„ì‚° =====

print("\n" + "=" * 60)
print("ğŸ¯ Step 5: Gap Index ê³„ì‚° (Need - Supply)")
print("=" * 60)

# í†µí•©
df_final = df[['district']].copy()
df_final = df_final.merge(df_need_norm[['district', 'Need_Index']], on='district')
df_final = df_final.merge(df_supply_norm[['district', 'Supply_Index']], on='district')

# Gap ê³„ì‚°
df_final['Gap_Index'] = df_final['Need_Index'] - df_final['Supply_Index']

# ì •ë ¬
df_final_sorted = df_final.sort_values('Gap_Index', ascending=False)

print("\nğŸš¨ Gap Index TOP 10 (ì •ì±… ê°œì… ìµœìš°ì„ ):")
print(df_final_sorted[['district', 'Need_Index', 'Supply_Index', 'Gap_Index']].head(10).to_string(index=False))

print("\nâœ… Gap Index BOTTOM 5 (ìƒëŒ€ì  ì•ˆì •):")
print(df_final_sorted[['district', 'Need_Index', 'Supply_Index', 'Gap_Index']].tail(5).to_string(index=False))

print(f"\ní‰ê·  Gap: {df_final['Gap_Index'].mean():.2f}")
print(f"ìµœëŒ€ Gap: {df_final['Gap_Index'].max():.2f}")
print(f"ìµœì†Œ Gap: {df_final['Gap_Index'].min():.2f}")

# 4ì‚¬ë¶„ë©´ ë¶„ë¥˜
median_need = df_final['Need_Index'].median()
median_supply = df_final['Supply_Index'].median()

def classify_quadrant(row):
    if row['Need_Index'] >= median_need and row['Supply_Index'] >= median_supply:
        return 'D: ê³ ìœ„í—˜ ëŒ€ì‘í˜•'
    elif row['Need_Index'] >= median_need and row['Supply_Index'] < median_supply:
        return 'C: ì‹¬ê° ë¶€ì¡±í˜• âš ï¸'
    elif row['Need_Index'] < median_need and row['Supply_Index'] >= median_supply:
        return 'B: ì–‘í˜¸í˜•'
    else:
        return 'A: ê³¼ì‰ê³µê¸‰í˜•'

df_final['Quadrant'] = df_final.apply(classify_quadrant, axis=1)

print("\nğŸ“Š 4ì‚¬ë¶„ë©´ ë¶„ë¥˜:")
print(df_final['Quadrant'].value_counts())

print("\nâœ… Step 5 ì™„ë£Œ: Gap Index ë° ë¶„ë¥˜")

# ===== ê²°ê³¼ ì €ì¥ =====

output_path = '/content/drive/MyDrive/Colab Notebooks/mhvi_project'

# ìµœì¢… ê²°ê³¼ ì €ì¥
df_final.to_csv(f'{output_path}/mhvi_final_result.csv', index=False, encoding='utf-8-sig')

print("\n" + "=" * 60)
print("ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
print("=" * 60)
print(f"íŒŒì¼: {output_path}/mhvi_final_result.csv")
print(f"\nì €ì¥ëœ ë³€ìˆ˜:")
print(f"  - district (êµ¬)")
print(f"  - Need_Index (ìœ„í—˜ë„)")
print(f"  - Supply_Index (ì¸í”„ë¼ ë¶€ì¡±ë„)")
print(f"  - Gap_Index (ê²©ì°¨)")
print(f"  - Quadrant (4ì‚¬ë¶„ë©´ ë¶„ë¥˜)")

print("\nğŸ‰ ë¶„ì„ ì™„ë£Œ!")
print("=" * 60)

import pandas as pd
import numpy as np

from sklearn.model_selection import LeaveOneOut, cross_val_predict
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# =========================
# 0) ë°ì´í„° ë¡œë“œ & ë³‘í•©
# =========================
need_path = "/content/drive/MyDrive/Colab Notebooks/mhvi_project/need_tidy.csv"
supply_path = "/content/drive/MyDrive/Colab Notebooks/mhvi_project/supply_tidy.csv"

need = pd.read_csv(need_path)
supply = pd.read_csv(supply_path)

df = need.merge(supply, on="district", how="inner").sort_values("district").reset_index(drop=True)

# =========================
# 1) X(í™˜ê²½) / y(íƒ€ê²Ÿ) ì •ì˜
# =========================
# íƒ€ê²Ÿ: ìì‚´ë¥  (ì›í•˜ë©´ depression_experience_rate ë“±ìœ¼ë¡œ ë°”ê¿”ë„ ë¨)
target = "suicide_rate"

# í™˜ê²½ ë³€ìˆ˜(ì„¤ëª… ë³€ìˆ˜): "êµ¬ì¡°/í™˜ê²½" + "ê³µê¸‰(ì •ì±… ë ˆë²„)"
# - êµ¬ì¡°/í™˜ê²½(ë‹¨ê¸° ì •ì±… ë ˆë²„ëŠ” ì•„ë‹ˆì§€ë§Œ ëª¨ë¸ ì„¤ëª…ë ¥ì— ë„ì›€)
structural_vars = [
    "elderly_population_rate",
    "unemployment_rate",
    "old_dependency_ratio",
    "single_households",
    "basic_livelihood_recipients",
]

# - ì •ì±… ë ˆë²„ í›„ë³´ (ì‹œë®¬ë ˆì´ì…˜í•  ë³€ìˆ˜)
policy_levers = [
    "welfare_budget_per_capita",
    "parks_count",
    "libraries_count",
    "public_sports_facilities_count",
    "medical_institutions_count",
    "health_promotion_centers_count",
    "elderly_leisure_welfare_facilities_count",
    "in_home_elderly_welfare_facilities_count",
    "cultural_satisfaction",
]

X_cols = structural_vars + policy_levers

# ê²°ì¸¡ ì²˜ë¦¬(ì•ˆì „)
df = df.dropna(subset=[target] + X_cols).copy()

X = df[X_cols]
y = df[target]

# =========================
# 2) ëª¨ë¸ í•™ìŠµ + LOOCV ì„±ëŠ¥ í™•ì¸
# =========================
rf = RandomForestRegressor(
    n_estimators=800,
    random_state=42,
    max_depth=None,
    min_samples_leaf=2,   # ì†Œí‘œë³¸ ê³¼ì í•© ì™„í™”
)

loo = LeaveOneOut()

# LOOCV ì˜ˆì¸¡(ê° êµ¬ë¥¼ í•œ ë²ˆì”© í…ŒìŠ¤íŠ¸ë¡œ)
y_pred_loo = cross_val_predict(rf, X, y, cv=loo)

mae = mean_absolute_error(y, y_pred_loo)
rmse = np.sqrt(mean_squared_error(y, y_pred_loo))
r2 = r2_score(y, y_pred_loo)

print("=== LOOCV ì„±ëŠ¥(ìì‚´ë¥  ì˜ˆì¸¡) ===")
print(f"MAE : {mae:.3f}")
print(f"RMSE: {rmse:.3f}")
print(f"R^2 : {r2:.3f}")

# ìµœì¢… ëª¨ë¸(ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ) -> ì •ì±… ì‹œë®¬ë ˆì´ì…˜ìš©
rf.fit(X, y)

# =========================
# 3) ì •ì±… ì‹œë‚˜ë¦¬ì˜¤(ë ˆë²„ ë³€í™”ëŸ‰) ì„¤ì •
# =========================
# "í˜„ì‹¤ì ì¸ ë³€í™”ëŸ‰"ì„ ì •í•´ì¤˜ì•¼ í•¨.
# - ì˜ˆì‚°: +10%
# - ë§Œì¡±ë„: +0.2 (ì²™ë„ì— ë§ì¶° ì¡°ì •)
# - ì‹œì„¤/ê°œìˆ˜: +10 (í˜¹ì€ +1, +3 ë“±ìœ¼ë¡œ ë°”ê¿”ë„ ë¨)
# ë°ì´í„° ìŠ¤ì¼€ì¼ì— ë§ì¶° ë§ˆìŒëŒ€ë¡œ ì¡°ì ˆ ê°€ëŠ¥!
scenario = {
    "welfare_budget_per_capita": ("pct", 0.10),     # +10%
    "cultural_satisfaction": ("add", 0.20),         # +0.2ì 
    "parks_count": ("add", 10),
    "libraries_count": ("add", 2),
    "public_sports_facilities_count": ("add", 2),
    "medical_institutions_count": ("add", 20),
    "health_promotion_centers_count": ("add", 1),
    "elderly_leisure_welfare_facilities_count": ("add", 10),
    "in_home_elderly_welfare_facilities_count": ("add", 5),
}

# =========================
# 4) êµ¬ë³„ ì •ì±… ì¶”ì²œ (Top-3)
# =========================
rows = []
for idx, row in df.iterrows():
    district = row["district"]
    x_base = row[X_cols].copy()

    # í˜„ì¬ ì˜ˆì¸¡
    y_base = rf.predict(pd.DataFrame([x_base]))[0]

    effects = []
    for lever, (mode, val) in scenario.items():
        x_new = x_base.copy()

        if mode == "add":
            x_new[lever] = x_new[lever] + val
        elif mode == "pct":
            x_new[lever] = x_new[lever] * (1.0 + val)
        else:
            raise ValueError(f"Unknown mode: {mode}")

        y_new = rf.predict(pd.DataFrame([x_new]))[0]
        delta = y_new - y_base  # ìŒìˆ˜ë©´ ê°œì„ (ìì‚´ë¥  ê°ì†Œ)

        effects.append((lever, delta, y_new))

    # ê°œì„  í° ìˆœ(ê°€ì¥ ìŒìˆ˜ë¶€í„°)
    effects.sort(key=lambda t: t[1])

    # top-3 ì €ì¥
    top3 = effects[:3]
    rows.append({
        "district": district,
        "pred_baseline": y_base,
        "rec1_lever": top3[0][0], "rec1_delta": top3[0][1],
        "rec2_lever": top3[1][0], "rec2_delta": top3[1][1],
        "rec3_lever": top3[2][0], "rec3_delta": top3[2][1],
    })

recommend_df = pd.DataFrame(rows).sort_values("rec1_delta")  # 1ìˆœìœ„ ê°œì„  í° êµ¬ ë¨¼ì €
print("\n=== êµ¬ë³„ ì •ì±… ì¶”ì²œ TOP-3 (ìì‚´ë¥  ì˜ˆì¸¡ ê°ì†Œ ê¸°ì¤€) ===")
print(recommend_df.head(10).to_string(index=False))

# ì €ì¥(ì›í•˜ë©´)
out_path = "/content/drive/MyDrive/Colab Notebooks/mhvi_project/policy_recommendations_rf.csv"
recommend_df.to_csv(out_path, index=False, encoding="utf-8-sig")
print(f"\nì €ì¥ ì™„ë£Œ: {out_path}")