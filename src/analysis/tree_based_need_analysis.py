"""
========================================
ìì‚´ë¥ -Need ì§€í‘œ ë™ë°˜ì„± ë¶„ì„
========================================

ëª©ì :
- ìì‚´ë¥ ì´ ë†’ì€ ì§€ì—­ì—ì„œ
  ì–´ë–¤ Need ì§€í‘œë“¤ì´ í•¨ê»˜ ë†’ê²Œ ë‚˜íƒ€ë‚˜ëŠ”ì§€ë¥¼ íƒìƒ‰
- "ì›ì¸ ê·œëª…"ì´ ì•„ë‹ˆë¼,
  ì§€ì—­ ë‹¨ìœ„ì—ì„œ ë°˜ë³µì ìœ¼ë¡œ ê´€ì°°ë˜ëŠ”
  êµ¬ì¡°ì  ë™ë°˜ íŒ¨í„´(co-occurrence)ì„ íŒŒì•…í•˜ëŠ” ê²ƒì´ ëª©ì 

ë°©ë²•:
- RandomForest íšŒê·€ ëª¨ë¸
- SHAPì„ ì´ìš©í•œ ë³€ìˆ˜ ê¸°ì—¬ë„ í•´ì„

ì£¼ì˜:
- ì¸ê³¼ê´€ê³„ ì¶”ë¡  ë¶ˆê°€ (n=25, ì†Œí‘œë³¸)
- ì˜ˆì¸¡ ì„±ëŠ¥ ê²½ìŸ ëª©ì  ì•„ë‹˜
- ì •ì±… íŒë‹¨ì„ ìœ„í•œ 'ì„¤ëª… ê°€ëŠ¥í•œ íƒìƒ‰ ë¶„ì„'
========================================
"""

import os
import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score
from sklearn.metrics import mean_squared_error, r2_score
import shap
import warnings
warnings.filterwarnings('ignore')

from config import BASE_DIR, DATA_DIR


def run_tree_based_analysis():
    """
    ìì‚´ë¥ -Need ì§€í‘œ ë™ë°˜ì„± ë¶„ì„ ë©”ì¸ í•¨ìˆ˜
    
    RandomForestì™€ SHAPì„ ì´ìš©í•˜ì—¬ ìì‚´ë¥ ê³¼ í•¨ê»˜ ë‚˜íƒ€ë‚˜ëŠ”
    Need ì§€í‘œë“¤ì˜ íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤.
    """
    
    # =====================================================
    # 1. ê²½ë¡œ ì„¤ì •
    # =====================================================
    INPUT_PATH = DATA_DIR / 'need_tidy.csv'
    OUTPUT_DIR = BASE_DIR / 'data' / 'outputs' / 'RandomForestModel'
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„±
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    # ë¶„ì„ ì‹œì‘ ë¡œê·¸
    print("=" * 60)
    print("ìì‚´ë¥ -Need ì§€í‘œ ë™ë°˜ì„± ë¶„ì„ (RandomForest + SHAP)")
    print("=" * 60)
    print(f"ì…ë ¥ íŒŒì¼: {INPUT_PATH}")
    print(f"ì¶œë ¥ ê²½ë¡œ: {OUTPUT_DIR}")
    print("=" * 60)
    
    # =====================================================
    # 2. ë°ì´í„° ë¡œë“œ
    # =====================================================
    df = pd.read_csv(INPUT_PATH)
    
    print(f"\nâœ“ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df.shape[0]}ê°œ ìì¹˜êµ¬, {df.shape[1]}ê°œ ë³€ìˆ˜")
    
    # =====================================================
    # 3. ë³€ìˆ˜ ë¶„ë¦¬
    # =====================================================
    y = df['suicide_rate'].values
    
    feature_cols = [
        col for col in df.columns
        if col not in ['district', 'suicide_rate']
    ]
    X = df[feature_cols].values
    
    print(f"\nâœ“ Target: suicide_rate")
    print(f"âœ“ Features ({len(feature_cols)}ê°œ):")
    for i, col in enumerate(feature_cols, 1):
        print(f"   {i}. {col}")
    
    # =====================================================
    # 4. RandomForest í•™ìŠµ
    # =====================================================
    RF_PARAMS = {
        'n_estimators': 300,
        'max_depth': 4,
        'min_samples_split': 3,
        'min_samples_leaf': 2,
        'max_features': 'sqrt',
        'random_state': 42,
        'n_jobs': -1
    }
    
    print(f"\n{'=' * 60}")
    print("RandomForest í•™ìŠµ ì‹œì‘")
    print(f"{'=' * 60}")
    for key, val in RF_PARAMS.items():
        print(f"  {key}: {val}")
    
    rf_model = RandomForestRegressor(**RF_PARAMS)
    rf_model.fit(X, y)
    
    # =====================================================
    # 5. ì˜ˆì¸¡ ë° ì„±ëŠ¥ í‰ê°€
    # =====================================================
    y_pred = rf_model.predict(X)
    
    train_r2 = r2_score(y, y_pred)
    train_rmse = np.sqrt(mean_squared_error(y, y_pred))
    
    cv_scores = cross_val_score(
        rf_model,
        X,
        y,
        cv=5,
        scoring='r2',
        n_jobs=-1
    )
    
    cv_r2_mean = cv_scores.mean()
    cv_r2_std = cv_scores.std()
    
    print(f"\n{'=' * 60}")
    print("ëª¨ë¸ ì„±ëŠ¥ (ì°¸ê³ ìš©)")
    print(f"{'=' * 60}")
    print(f"  Train RÂ²:  {train_r2:.4f}")
    print(f"  Train RMSE: {train_rmse:.4f}")
    print(f"  CV RÂ² (5-fold): {cv_r2_mean:.4f} (Â±{cv_r2_std:.4f})")
    print(f"\nâš ï¸ ì£¼ì˜: n=25 ì†Œí‘œë³¸ì´ë¯€ë¡œ ì„±ëŠ¥ ì§€í‘œëŠ” ì°¸ê³ ìš©")
    print(f"    â†’ ì˜ˆì¸¡ ì„±ëŠ¥ë³´ë‹¤ 'ë³€ìˆ˜ ê°„ ë™ë°˜ì„± íŒ¨í„´' íŒŒì•…ì´ ëª©ì ")
    print(f"{'=' * 60}")
    
    # =====================================================
    # 6. Feature Importance ì¶”ì¶œ
    # =====================================================
    importance_df = pd.DataFrame({
        'feature': feature_cols,
        'importance': rf_model.feature_importances_
    })
    
    importance_df = importance_df.sort_values(
        'importance',
        ascending=False
    )
    importance_df['importance_rank'] = range(
        1, len(importance_df) + 1
    )
    
    fi_path = OUTPUT_DIR / 'rf_feature_importance.csv'
    importance_df.to_csv(
        fi_path,
        index=False,
        encoding='utf-8-sig'
    )
    
    print(f"\nâœ“ Feature Importance ì €ì¥: {fi_path}")
    print("\n[Feature Importance Top 5]")
    print(importance_df.head().to_string(index=False))
    
    # =====================================================
    # 7. SHAP ë¶„ì„
    # =====================================================
    print(f"\n{'=' * 60}")
    print("SHAP ë¶„ì„ ì‹œì‘ (TreeExplainer)")
    print(f"{'=' * 60}")
    
    explainer = shap.TreeExplainer(rf_model)
    shap_values = explainer.shap_values(X)
    
    shap_summary = pd.DataFrame({
        'feature': feature_cols,
        'mean_abs_shap_value': np.abs(shap_values).mean(axis=0)
    })
    
    shap_summary = shap_summary.sort_values(
        'mean_abs_shap_value',
        ascending=False
    )
    shap_summary['shap_rank'] = range(
        1, len(shap_summary) + 1
    )
    
    shap_path = OUTPUT_DIR / 'rf_shap_summary.csv'
    shap_summary.to_csv(
        shap_path,
        index=False,
        encoding='utf-8-sig'
    )
    
    print(f"\nâœ“ SHAP Summary ì €ì¥: {shap_path}")
    print("\n[SHAP Importance Top 5]")
    print(shap_summary.head().to_string(index=False))
    
    # =====================================================
    # 8. ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
    # =====================================================
    predictions_df = pd.DataFrame({
        'district': df['district'],
        'suicide_rate_actual': y,
        'suicide_rate_predicted': y_pred,
        'residual': y - y_pred
    })
    
    pred_path = OUTPUT_DIR / 'rf_predictions.csv'
    predictions_df.to_csv(
        pred_path,
        index=False,
        encoding='utf-8-sig'
    )
    
    print(f"\nâœ“ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: {pred_path}")
    
    # =====================================================
    # 9. ê²°ê³¼ í•´ì„ ê°€ì´ë“œ
    # =====================================================
    print(f"\n{'=' * 60}")
    print("ğŸ“Š ê²°ê³¼ í•´ì„ ê°€ì´ë“œ (ì•ˆì „í•œ í‘œí˜„)")
    print(f"{'=' * 60}")
    print("""
âœ… ì˜¬ë°”ë¥¸ í•´ì„ (ë™ë°˜ì„±/íŒ¨í„´):
  â€¢ "ìì‚´ë¥ ì´ ë†’ì€ ìì¹˜êµ¬ì—ì„œ {ë³€ìˆ˜ëª…}ë„ í•¨ê»˜ ë†’ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ê²½í–¥"
  â€¢ "{ë³€ìˆ˜ëª…}ì€ ìì‚´ë¥  ë³€ë™ê³¼ ê°•í•œ ë™ë°˜ì„±ì„ ë³´ì„"
  â€¢ "RandomForest ëª¨ë¸ì´ ìì‚´ë¥  íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” ë° {ë³€ìˆ˜ëª…}ì„ ì£¼ìš” íŠ¹ì§•ìœ¼ë¡œ í™œìš©"
  â€¢ "SHAP ë¶„ì„ ê²°ê³¼, {ë³€ìˆ˜ëª…}ì´ ì˜ˆì¸¡ì— ê°€ì¥ í° ê¸°ì—¬"

âŒ í”¼í•´ì•¼ í•  í•´ì„ (ì¸ê³¼/ì •ì±…):
  â€¢ "{ë³€ìˆ˜ëª…}ì´ ìì‚´ë¥ ì„ ì¦ê°€/ê°ì†Œì‹œí‚¨ë‹¤" â†’ ì¸ê³¼ê´€ê³„ ì£¼ì¥ ë¶ˆê°€
  â€¢ "{ë³€ìˆ˜ëª…}ì„ ê°œì„ í•˜ë©´ ìì‚´ë¥ ì´ ë‚®ì•„ì§„ë‹¤" â†’ ì •ì±… íš¨ê³¼ ì¶”ì • ë¶ˆê°€
  â€¢ "ì´ ëª¨ë¸ë¡œ ë¯¸ë˜ ìì‚´ë¥  ì˜ˆì¸¡ ê°€ëŠ¥" â†’ n=25, ì˜ˆì¸¡ ëª©ì  ì•„ë‹˜

ğŸ” ë§¥ë½:
  - n=25 (ì„œìš¸ì‹œ ìì¹˜êµ¬) ì†Œí‘œë³¸ â†’ í†µê³„ì  ì¼ë°˜í™” ì œí•œì 
  - ì§€ì—­ ë‹¨ìœ„ ì§‘ê³„ ë°ì´í„° â†’ ìƒíƒœí•™ì  ì˜¤ë¥˜(ecological fallacy) ê°€ëŠ¥ì„±
  - íŠ¸ë¦¬ ëª¨ë¸ íŠ¹ì„±ìƒ ë¹„ì„ í˜•/ìƒí˜¸ì‘ìš© íŒ¨í„´ í¬ì°©
  - ë³¸ ë¶„ì„ì€ 'íƒìƒ‰ì (exploratory)' ì„±ê²©
""")
    
    print(f"\n{'=' * 60}")
    print("âœ… ë¶„ì„ ì™„ë£Œ")
    print(f"{'=' * 60}")
    print(f"ì €ì¥ëœ íŒŒì¼:")
    print(f"  1. {fi_path}")
    print(f"  2. {shap_path}")
    print(f"  3. {pred_path}")
    print(f"{'=' * 60}\n")
    
    # =====================================================
    # 10. ìš”ì•½ í†µê³„ ì¶œë ¥
    # =====================================================
    print("ğŸ“ˆ ìš”ì•½ í†µê³„")
    print(f"{'=' * 60}")
    print(f"ìµœê³  ì¤‘ìš”ë„ ë³€ìˆ˜ (Feature Importance):")
    print(f"  â†’ {importance_df.iloc[0]['feature']}")
    print(f"     (importance: {importance_df.iloc[0]['importance']:.4f})")
    print(f"\nìµœê³  ì¤‘ìš”ë„ ë³€ìˆ˜ (SHAP):")
    print(f"  â†’ {shap_summary.iloc[0]['feature']}")
    print(f"     (mean |SHAP|: {shap_summary.iloc[0]['mean_abs_shap_value']:.4f})")
    print(f"{'=' * 60}\n")


# =====================================================
# ì‹¤í–‰ ì§„ì…ì 
# =====================================================
def main():
    """ì§ì ‘ ì‹¤í–‰ ì‹œ ì‚¬ìš©"""
    run_tree_based_analysis()


if __name__ == "__main__":
    main()